**Универсальный процесс машинного обучения состоит из трех частей:**

1. **Определение задачи** — изучите предметную область и бизнес-логику, лежащую в основе того, о чем просит заказчик. Выполните сбор и первичный анализ данных и выберите критерий оценки успеха в решении задачи. 

2. **Разработка модели** — подготовьте данные для передачи в модель машинного обучения; выберите протокол оценки модели и простой базовый уровень, который нужно превзойти; обучите первую модель, обладающую способностью к обобщению и переобучению, а затем настраивайте ее и применяйте регуляризацию, пока не будет достигнуто максимально возможное качество обобщения. 

3. **Развертывание модели** — представьте результаты заинтересованным сторонам; перенесите модель на веб-сервер, в мобильное приложение, веб-страницу или встроенное устройство; наблюдайте за качеством работы модели в реальном времени и начинайте сбор данных, которые вам понадобятся при строительстве модели следующего поколения.

Каждый процесс подробнее далее.

## Определение задачи

Определение задачи состоит из трех важный частей: формулировка задачи, cбор данных, первичный анализ данных, выбор меры успеха.

### Формулировка задачи

Формулировка задачи машинного обучения обычно требует детального обсуждения с заинтересованными сторонами. Вот вопросы, которые вы должны держать в голове: 

- Какой вид будут иметь входные данные? Что требуется предсказать? Вы сможете обучить сеть предполагать что-либо только при наличии обучающих данных: например, обучить сеть определять оценку в отзывах к фильмам можно, если имеются отзывы и соответствующие аннотации. То есть доступность данных на данном этапе является ограничивающим фактором. Во многих случаях вам придется прибегать к сбору и аннотированию новых наборов данных самостоятельно (о чем мы поговорим в следующем разделе). 

- К какому типу относится задача, стоящая перед вами? Бинарная классификация? Многоклассовая классификация? Скалярная регрессия? Векторная регрессия? Многоклассовая многозначная (нечеткая) классификация? Сегментация изображения? Определение рейтинга? Что-то иное, например кластеризация, генерация или обучение с подкреплением? В некоторых случаях может оказаться, что машинное обучение не лучший способ обработки данных и следует использовать что-то еще, например старый добрый статистический анализ.

- Как выглядят существующие решения? Возможно, у вашего клиента уже есть созданный вручную алгоритм, выполняющий фильтрацию спама или выявляющий мошенничество с кредитными картами с использованием множества вложенных операторов if. Может, в настоящее время задача решается человеком, который, например, наблюдает за конвейерной лентой на заводе по производству печенья и вручную удаляет бракованные изделия или составляет списки воспроизведения с рекомендациями для рассылки пользователям, которым понравился конкретный исполнитель. Вы должны убедиться, что понимаете, какие системы уже существуют и как они работают. 

- Есть ли какие-то особые ограничения, с которыми вам придется столкнуться? Например, может выясниться, что приложение, для которого нужно создать систему обнаружения спама, в обязательном порядке шифрует сообщения, поэтому разрабатываемая модель должна функционировать на телефоне конечного пользователя и обучаться на внешнем наборе данных. Возможно, модель выявления бракованных печений имеет такие ограничения по задержкам, что ее придется запускать на встроенном устройстве на заводе, а не на удаленном сервере. Вы должны знать и понимать все условия, в которых придется работать вашей модели. После проведения исследований хорошо иметь более или менее полное представление о том, какими должны быть входные данные и целевые значения и какой тип задачи машинного обучения соответствует вашей проблеме. Не забывайте о гипотезах, которые выдвигаются на этом этапе: 
	
	- гипотеза о том, что выходные данные можно предсказать по входным данным;
	
	- гипотеза о том, что доступные данные достаточно информативны для изучения отношений между входными и выходными данными. 

Пока у вас нет рабочей модели, это всего лишь идеи, ожидающие подтверждения или опровержения. Не все задачи имеют решение; наличие входных данных X и целей Y еще не означает, что X содержит достаточно информации для предсказания Y. Например, если вы пытаетесь предсказать движение акций на фондовой бирже по недавней истории изменения цен, вы едва ли добьетесь успеха, потому что история цен не содержит достаточного объема информации для уверенного прогнозирования.

## Сбор данных

Определив природу задачи и узнав, какими должны быть входные данные и цели, можно приступать к сбору данных — наиболее сложной, трудоемкой и дорогостоящей части большинства проектов машинного обучения. Хороший набор данных — это актив, в который стоит вкладывать время и силы. Если у вас есть дополнительные 50 часов, которые можно потратить на проект, то лучше отдать их на сбор дополнительных данных, а не на поиск улучшений в моделировании.

Процесс маркировки данных определяет качество целевых значений, которые, в свою очередь, определяют качество модели. Внимательно изучите доступные вам варианты такие, как: 

- самостоятельная маркировка данных; 

- маркировка с привлечением краудсорсинговой платформы (такой как Mechanical Turk); 

- помощь специализированной компании по маркировке данных.

Аутсорсинг (маркировка сторонними исполнителями) может помочь сэкономить ваше время и деньги, но лишает вас контроля. Использование такой платформы, как Mechanical Turk, вероятно, обойдется еще дешевле, но качество маркировки может оказаться довольно низким. Оценивая варианты, учитывайте имеющиеся ограничения:

- Должны ли быть экспертами в предметной области те, кто будет заниматься маркировкой данных, или это под силу любому? Отбором изображений для задачи классификации кошек и собак может заниматься любой, но для определения пород собак нужны специальные знания; маркировка же, к примеру, компьютерных томограмм переломов костей и вовсе требует степени доктора медицины. 

- Если маркировка данных требует специальных знаний, то сможете ли вы обучить других людей? Если нет, то как привлечь к этой работе экспертов? 

- Понимаете ли вы сами, как эксперты маркируют данные? Если нет, то вам придется рассматривать свой набор данных как черный ящик и у вас не будет возможности проектирования признаков вручную — это некритично, но может стать ограничивающим фактором.

Если вы решите маркировать данные самостоятельно, то спросите себя, какое программное обеспечение будете использовать для записи меток. Возможно, вам придется его разработать самим. Эффективное программное обеспечение для маркировки данных может помочь сэкономить много времени, поэтому уделите ему должное внимание на ранней стадии развития проекта.

Если есть возможность, собирайте данные непосредственно в том окружении, где будет использоваться модель. Модель классификации отзывов о фильмах следует применять к новым обзорам в IMDB, а не к обзорам ресторанов Yelp или статусам в Twitter. Если вам нужно оценивать эмоциональную окраску твитов, начните со сбора и маркировки реальных твитов в той же группе пользователей, которые, как предполагается, будут использовать модель. Если нет возможности обучить модель на реальных данных, постарайтесь как можно полнее определить, чем ваши обучающие данные отличаются от реальных, и устраните эти различия.

### Первичный анализ данных

Представлять набор данных как черный ящик — не лучшее решение. Прежде чем приступить к обучению моделей, обязательно проанализируйте свои данные, чтобы понять, какие особенности дают им прогнозирующую способность, что поможет обоснованно спроектировать признаки и выявить потенциальные проблемы.

### Выбор меры успеха

Чтобы держать ситуацию под контролем, нужно иметь возможность наблюдать за ней. Чтобы добиться успеха, важно определить, что понимается под успехом. Близость? Точность и полнота? Удержание клиентов? Мера успеха будет определять все технические решения, которые вы будете принимать в процессе работы над проектом. Она должна быть прямо связана с вашими общими целями — например, такими, как успех бизнеса. 

Для задач симметричной классификации, когда каждый класс одинаково вероятен, часто используются такие показатели, как близость и площадь под кривой рабочей характеристики приемника (area under curve of receiver operating characteristic, ROC AUC). Для задач несимметричной классификации можно взять точность и полноту. Для задач ранжирования или многозначной классификации пригодится среднее математическое ожидание. Также нередко приходится определять собственную меру успеха. Чтобы получить представление о разнообразии мер успеха в машинном обучении и их связях с разными предметными областями, полезно ознакомиться с состязаниями аналитиков на сайте [Kaggle](https://kaggle.com); там вы увидите широкий спектр проблем и оцениваемых показателей.

## Разработка модели

Определившись с мерой оценки прогресса, можно приступать к разработке модели. В большинстве руководств и исследовательских проектов предполагается, что разработка модели — это единственный шаг, поэтому пропускаются такие этапы, как определение задачи и сбор данных (которые, как предполагается, уже выполнены), а также развертывание и обслуживание модели (которые, как принято считать, будут выполняться кем-то другим). На самом деле разработка модели — лишь один из множества шагов в процессе машинного обучения, и не самый сложный. Самое сложное — это формулировка задачи, а также сбор, маркировка и очистка данных.

### Подготовка данных

Редко модели глубокого обучения принимают исходные данные в необработанном виде. Цель предварительной обработки — сделать исходные данные более доступными для нейронных сетей. Обработка может заключаться в векторизации, нормализации или восстановлении пропущенных значений. Многие методы предварительной обработки зависят от предметной области (например, текстовые данные и изображения обрабатываются по разному).

#### Векторизация

Желательно, чтобы все входы и цели в нейронной сети были тензорами чисел с плавающей точкой (или в особых случаях тензорами целых чисел). Какие бы данные вам ни требовалось обработать — звук, изображение, текст, — их сначала нужно преобразовать в тензоры. Этот шаг называется векторизацией данных.

#### Нормализация значений

Вообще, небезопасно передавать в нейронную сеть данные, принимающие очень большие значения (например, целые числа с большим количеством значимых разрядов, которые намного больше начальных значений, принимаемых весами сети), или разнородные данные (например, такие, в которых один признак определяется значениями в диапазоне 0–1, а другой — в диапазоне 100–200). Это может привести к значительным изменениям градиента, которые будут препятствовать сходимости сети. Чтобы упростить обучение сети, данные должны:

- **Принимать небольшие значения** — как правило, значения должны находиться в диапазоне 0–1;

- **Быть однородными** — то есть все признаки должны принимать значения примерно из одного и того же диапазона.

Кроме того, может оказаться полезной (хотя и не всегда необходимой) следующая практика нормализации: 

- Нормализация каждого признака независимо таким образом, чтобы его среднее значение было равно 0; 

- Нормализация каждого признака независимо таким образом, чтобы его стандартное отклонение было равно 1.

**Реализация при помощи [[NumPy|NumPy]]:**

```Python
# Предполагается, что x — это двумерная матрица данных с формой (образцы, свойства)
x -= x.mean(axis=0)
x /= x.std(axis=0)
```

#### Обработка недостающих значений

Иногда в исходных данных могут отсутствовать некоторые значения. Например, в случае с предсказанием цен на дома первым признаком (столбец с индексом 0 в данных) был уровень преступности на душу населения. Как быть, если этот признак определен не во всех образцах? Если оставить все как есть, у нас появится недостаток значений в обучающих или контрольных данных. От такого признака можно вообще отказаться, а можно поступить иначе:

- Если признак категориальный, то можно создать новую категорию, которая будет означать «отсутствие признака». Модель автоматически узнает, что это означает по отношению к целям. 

- Если признак числовой, желательно избегать использования произвольного значения (например, 0) — это может создать разрыв в скрытом пространстве, образованном признаками, из-за чего обучаемой модели будет труднее найти обобщающее решение. Вместо этого можно попробовать заменить отсутствующие значения средним или медианным значением для конкретного признака в наборе данных. Также можно обучить модель предсказывать отсутствующие значения одних признаков по значениям других.

Обратите внимание: если в контрольных данных имеются отсутствующие значения, а сеть была обучена без них, то она не будет отсутствующие значения распознавать! В этой ситуации следует искусственно сгенерировать обучающие экземпляры с отсутствующими признаками: скопируйте несколько обучающих образцов и отбросьте в них некоторые признаки, которые, как ожидается, не определены в контрольных данных.

### Выбор протокола оценки

Цель модели — добиться обобщения, и каждое решение, которое вы будете принимать в процессе разработки модели, будет зависеть от метрик на этапе проверки, оценивающих эффективность обобщения. Цель протокола оценки — точно оценить выбранную вами меру успеха (например, точность) на реальных данных. Надежность этого процесса имеет решающее значение для построения полезной модели. Три распространенных протокола оценки:

- Выделение из общей выборки отдельного проверочного набора данных — этот способ хорошо подходит при наличии большого объема данных; 

- Перекрестная проверка по K блокам — оптимальный вариант при небольшом количестве исходных образцов, из которых нельзя выделить представительную выборку для проверки; 

- Итерационная проверка по K блокам с перемешиванием — позволяет с высокой точностью оценить модель, когда в вашем распоряжении имеется ограниченный объем данных.

### Преодоление базового случая

Первая цель — достичь статистической мощности, то есть разработать небольшую модель, способную выдать более качественный результат по сравнению с базовым случаем. На этом этапе следует сосредоточить внимание на таких трех важных аспектах, как:

- Конструирование признаков — отфильтруйте неинформативные признаки (отбор признаков) и используйте свои знания в предметной области для конструирования новых признаков, которые могут оказаться полезными; 

- Выбор правильной архитектуры — какую архитектуру вы будете использовать: плотно связанную, сверточную, рекуррентную нейронную сеть или трансформер (Transformer)? Подходит ли в целом глубокое обучение для решения данной задачи, или лучше использовать что-то еще; 

- Выбор подходящей конфигурации обучения — какую функцию потерь, размер пакета и скорость обучения лучше использовать.

**Таблица выбора функций активации и потерь для типичных задач:**

| Тип задачи                                | Функция активации для последнего уровня | Функция потерь            |
| ----------------------------------------- | --------------------------------------- | ------------------------- |
| Бинарная классификация                    | sigmoid                                 | binary_crossentropy       |
| Многоклассовая однозначная классификация  | softmax                                 | categorical_ crossentropy |
| Многоклассовая многозначная классификация | sigmoid                                 | binary_crossentropy       |

### Разработка модели с переобучением

После получения модели, обладающей статистической мощностью, встает вопрос о достаточной мощности модели. Достаточно ли слоев и параметров, чтобы правильно смоделировать задачу? Например, модель логистической регрессии будет иметь некоторую статистическую мощность для классификации цифр из набора MNIST, но этой мощности не будет достаточно, чтобы считать задачу решенной. Не забывайте о распространенной проблеме машинного обучения — противоречии между оптимизацией и общностью; идеальной считается модель, которая стоит непосредственно на границе между недообучением и переобучением, между недостаточной и избыточной емкостью. Чтобы понять, где пролегает эта граница, ее сначала нужно пересечь. Для оценки того, насколько большой должна быть модель, сначала нужно сконструировать модель, обладающую эффектом переобучения:

- Добавьте слои.

- Задайте большое количество параметров в слоях.

- Обучите модель на большом количестве эпох.

Постоянно контролируйте, как меняется уровень потерь на этапах обучения и проверки, а также любые другие показатели на этих же этапах, которые вас интересуют. Ухудшение качества модели на проверочных данных свидетельствует о достижении эффекта переобучения.

### Регуляризация и настройка модели

Получив модель, обладающую статистической мощностью, и добившись ее переобучения, вы будете спокойны в том, что движетесь в верном направлении. С этого момента вашей целью становится максимизация общности. Этот этап занимает больше всего времени: вам придется многократно изменять свою модель, обучать ее, оценивать качество на проверочных данных (контрольные данные не должны принимать здесь никакого участия), снова изменять ее и повторять цикл, пока качество модели не достигнет желаемого уровня. Вот кое-что из того, что вы должны попробовать:

- Добавить прореживание;

- Опробовать разные архитектуры, добавлять и удалять слои;

- Если модель не очень большая, то добавить L1- и/или L2-регуляризацию;

- Опробовать разные гиперпараметры (например, число нейронов на слой или шаг обучения оптимизатора), чтобы найти оптимальные настройки;

- Дополнительно можно выполнить цикл курирования данных или конструирования признаков: собрать больше данных и выполнить их маркировку, добавить новые признаки или удалить имеющиеся, которые не кажутся информативными. 

Большую часть подобной работы можно автоматизировать с помощью программного обеспечения для автоматической настройки гиперпараметров, такого как KerasTuner. 

Получив удовлетворительную конфигурацию, можно обучить окончательный вариант модели на всех доступных данных (обучающих и проверочных) и оценить ее качество на контрольном наборе. Если качество модели на контрольных данных окажется значительно хуже, чем на проверочных, это может означать, что ваша процедура проверки была ненадежной или в процессе настройки параметров модели проявился эффект переобучения на проверочных данных. Тогда можно попробовать переключиться на использование другого, более надежного протокола оценки (такого как итерационная проверка по K блокам с перемешиванием).

## Развертывание модели

Ваша модель успешно прошла окончательную оценку на контрольном наборе и готова начать свою плодотворную деятельность.

### Объяснение особенностей работы модели заинтересованным сторонам и обозначение границ ожидаемого

Успех и доверие клиентов возможны, только если модель соответствует ожиданиям или превосходит их. Фактическая система, которую вы вводите в эксплуатацию, — это только половина дела; другая половина — обозначение перед выпуском границ ожидаемого. 

Неспециалисты часто имеют чересчур завышенные требования в отношении систем искусственного интеллекта. Например, они могут ожидать, что система «понимает» свою задачу и способна проявлять человеческий здравый смысл в ее контексте. Чтобы решить эту проблему, устройте демонстрацию некоторых примеров отказа вашей модели (например, покажите, как выглядят неправильно классифицированные образцы, особенно те, для которых неправильная классификация кажется неожиданной).

Избегайте абстрактных утверждений типа «модель имеет точность 98 %» (которые большинство людей мысленно округляют до 100 %) и лучше сообщайте, например, о частоте ложноположительных и ложноотрицательных результатов. Вы могли бы сказать: «С этими настройками модель будет ложно квалифицировать действия как мошеннические в 5 % случаев и пропускать фактическое мошенничество в 2,5 % случаев. Ежедневно в среднем 200 законных транзакций будут идентифицированы как мошеннические и отправлены на ручную проверку, 14 мошеннических транзакций будут пропущены и 266 будут идентифицированы верно». Четко соотнесите показатели эффективности модели с бизнес-целями.

### Предоставление доступа к модели

Работа над проектом машинного обучения не заканчивается в тот момент, когда вы доберетесь до блокнота Colab и сохраните там обученную модель. Вообще, модели редко передаются в эксплуатацию в виде объекта на Python, которым вы манипулировали во время обучения. 

Во-первых, вам может потребоваться экспортировать модель в какое-то другое окружение, отличное от Python: 

- Если ваше промышленное окружение вообще не поддерживает Python — например, это мобильное приложение или встраиваемая система; 

- Если остальная часть приложения написана не на Python (а на JavaScript, C++ и т. д.) — в таком случае использование Python для обслуживания модели может повлечь значительные накладные расходы. 

Во-вторых, поскольку модель будет использоваться только для прогнозирования (эта фаза называется выводом), а не для обучения, вы можете применить различные оптимизации, которые помогут ускорить модель и уменьшить объем используемой памяти.

#### Развертывание модели в виде REST API

Это, пожалуй, самый распространенный способ предоставления доступа к модели для получения прогнозов: установите TensorFlow на сервере или в облачном экземпляре и посылайте запросы модели через REST API. Для этого можно создать свое обслуживающее приложение, например, на основе Flask (или любой другой библиотеки для разработки веб-приложений на Python) или использовать библиотеку, входящую в состав фреймворка TensorFlow и предназначенную для предоставления доступа к моделям через API, которая называется [TensorFlow Serving](www.tensorflow.org/tfx/guide/serving). TensorFlow Serving позволяет развернуть модель Keras за считаные минуты.

Данный вариант развертывания следует использовать: 

- Когда приложение, использующее модель для прогнозирования, имеет надежное соединение с интернетом (что очевидно, ведь приложение не сможет получать прогнозы из удаленного API, если мобильное устройство перевести в режим полета или разместить там, где доступ к интернету ограничен); 

- Когда приложение не имеет строгих требований к задержке: обработка запроса, вычисление прогноза и передача ответа обычно занимают около 500 миллисекунд; 

- Для получения прогноза не требуется передавать конфиденциальные данные, потому что данные должны быть доступны модели в расшифрованном виде (но помните, что HTTP-запросы и ответы должны шифроваться с использованием протокола SSL).

Системы поиска изображений, подбора музыкальных рекомендаций, выявления мошеннических действий с кредитными картами и анализа спутниковых изображений вполне могут обслуживать пользователей через REST API. П

Перед развертыванием модели в виде REST API вам также придется ответить на очень важный вопрос: будете ли вы размещать код на своем сервере или предпочтете использовать стороннюю облачную службу. Например, Cloud AI Platform, продукт компании Google, позволяет выгрузить модель TensorFlow в Google Cloud Storage (GCS) и получить конечную точку API для отправки запросов. Платформа сама позаботится о таких тонкостях, как обслуживание пакетных прогнозов, балансировка нагрузки и масштабирование.

#### Развертывание модели на устройстве

В некоторых случаях желательно, чтобы модель работала на том же устройстве, где выполняется использующее ее приложение. Это может быть смартфон, встроенная в робота система на процессоре ARM или микроконтроллер в небольшом устройстве. Вероятно, вы видели камеру, способную автоматически обнаруживать людей и распознавать их лица: вполне возможно, что это результат работы небольшой модели глубокого обучения, действующей непосредственно в камере.

Данный вариант развертывания следует использовать, когда: 

- Модель имеет строгие ограничения по задержке или должна работать в отсутствие подключения к интернету. Например, в захватывающем приложении с функцией дополненной реальности задержки на ожидание ответа удаленного сервера просто недопустимы; 

- Модель нужно сделать достаточно маленькой, чтобы она могла работать в условиях ограниченного объема доступной памяти и на процессоре небольшой мощности. В таких случаях вам может помочь набор инструментов TensorFlow Model Optimization Toolkit (www.tensorflow.org/model_optimization); 

- Точность прогнозирования не является критической для вашей задачи. Высокая точность и быстродействие — это два взаимоисключающих фактора, поэтому в условиях ограниченного объема памяти и невысокой вычислительной мощности часто приходится развертывать модель, которая не так хороша, как ее версия, требующая для работы мощный графический процессор; 

- Входные данные строго конфиденциальны и не должны появляться в открытом виде на удаленном сервере.

Например, модель обнаружения спама должна запускаться на смартфоне конечного пользователя в составе чат-приложения, поскольку сообщения подвергаются сквозному шифрованию и не могут быть прочитаны удаленной моделью. Точно так же модель обнаружения бракованного печенья на ленте конвейера имеет строгие ограничения по задержке и должна работать непосредственно на заводе. К счастью, в этом случае нет ограничений по мощности или объему памяти и модель можно запустить на графическом процессоре. 

Для развертывания моделей Keras на смартфонах или встраиваемых устройствах можно использовать решениеTensorFlow Lite (www.tensorflow.org/lite). Этот фреймворк обеспечивает эффективную работу моделей глубокого обучения в режиме прогнозирования на смартфонах с Android и iOS, а также на компьютерах на базе ARM64, Raspberry Pi и некоторых микроконтроллерах. Он включает инструмент для преобразования моделей Keras в формат TensorFlow Lite.

#### Развертывание модели в браузере

Модели глубокого обучения часто применяются в приложениях на JavaScript, выполняющихся в браузере или в настольной версии. Конечно, приложение можно реализовать так, что оно будет обращаться к удаленной модели через REST API, но иногда использование модели непосредственно в браузере на компьютере пользователя дает важные преимущества (с задействованием ресурсов графического процессора, если он доступен). Данный вариант развертывания следует использовать, когда: 

- Вы хотите переложить нагрузку на оборудование конечного пользователя и за счет этого уменьшить нагрузку на сервер; входные данные должны оставаться на компьютере или телефоне конечного пользователя. Например, модель обнаружения спама в настольной и веб версии чат-приложения (реализованного как кросс-платформенное приложение на JavaScript) должна выполняться локально; 

- Приложение имеет строгие ограничения по задержке. Конечно, модель, работающая на ноутбуке или смартфоне конечного пользователя, почти наверняка будет функционировать медленнее, чем на мощном графическом процессоре вашего сервера, зато ей не потребуются дополнительные 100 миллисекунд на транспортировку данных по сети; 

- Приложение должно продолжать работу в отсутствие подключения к интернету, после того как модель будет загружена и сохранена в локальном кэше.

Выбирайте этот вариант, только если ваша модель достаточно мала и нетребовательна к вычислительным ресурсам или объему оперативной памяти ноутбука или смартфона пользователя. Кроме того, поскольку модель будет загружена на устройство пользователя, вы должны гарантировать отсутствие в ней любой конфиденциальной информации. Помните, что из обученной модели глубокого обучения часто можно восстановить некоторую информацию об обучающих данных: если модель была обучена на конфиденциальных данных, ее лучше не выкладывать в общий доступ.

Чтобы развернуть модель на JavaScript, экосистема TensorFlow включает TensorFlow.js (www.tensorflow.org/js), библиотеку JavaScript для глубокого обучения, которая реализует почти все возможности Keras (изначально она разрабатывалась под рабочим названием WebKeras), а также множество низкоуровневых функций TensorFlow API. Готовую модель Keras можно без особого труда импортировать в TensorFlow.js, чтобы затем использовать ее в составе браузерного приложения на JavaScript или настольного приложения Electron.\

#### Оптимизация обученной модели

Оптимизация обученной модели особенно важна при развертывании в окружении со строгими ограничениями на доступную вычислительную мощность и объем памяти (смартфоны и встраиваемые устройства) или с жесткими требованиями к задержке. Всегда старайтесь оптимизировать модель перед импортом в TensorFlow.js или экспортом в TensorFlow Lite. Вот два популярных метода оптимизации, которые можно применить:

- Усечение весов — не все коэффициенты в тензоре весов одинаково влияют на прогнозы. Порой можно значительно уменьшить количество параметров в слоях модели, сохранив только самые важные. Это поможет снизить потребление памяти и вычислительных ресурсов вашей моделью при небольшом ухудшении качества ее прогнозов. Выбирая параметры для удаления, можно контролировать соотношение размера и точности модели;

- Квантование весов — модели глубокого обучения обучаются за счет корректировки весов с плавающей точкой одинарной точности (float32). Однако веса можно квантовать до 8-битных целых чисел со знаком (int8), чтобы получить модель исключительно для прогнозирования, которая в четыре раза меньше, но показывает точность, близкую к исходной.

Экосистема TensorFlow включает набор инструментов для усечения и квантования весов (www.tensorflow.org/model_optimization), глубоко интегрированный с Keras API.

### Мониторинг качества работы модели в процессе эксплуатации

Итак, вы экспортировали обученную модель, интегрировали ее в свое приложение, опробовали ее на реальных данных — и она повела себя ровно так, как вы ожидали. Вы написали модульные тесты, а также реализовали журналирование и мониторинг состояния. Отлично! Теперь пришло время нажать большую красную кнопку и развернуть модель в рабочем окружении. 

Но это еще не конец. После развертывания модели нужно постоянно наблюдать за ее поведением, качеством прогнозов на новых данных, взаимодействием с остальной частью приложения и ее возможным влиянием на бизнес-показатели:

- Увеличилась ли вовлеченность пользователей вашей онлайн-радиостанции после внедрения новой системы рекомендаций музыки? Увеличился ли средний процент переходов по рекламным ссылкам после развертывания новой модели прогнозирования? Подумайте о проведении рандомизированного A/B-тестирования, чтобы отделить эффект влияния модели от других изменений: подмножество обращений должно обрабатываться с использованием новой модели, а другое контрольное подмножество — с применением старой процедуры. После обработки достаточно большого количества обращений разница в результатах почти наверняка будет связана с моделью. 

- Если возможно, регулярно проводите ручной аудит прогнозов модели по реальным данным. Обычно при этом можно использовать ту же инфраструктуру, что и для маркировки данных: отправить некоторую часть реальных данных для маркировки вручную и сравнить прогнозы модели с новыми метками. Это обязательно следует делать, например, для системы поиска изображений и системы отбраковки печенья. 

- Если аудит вручную невозможен, подумайте об альтернативных способах оценки, таких как опрос пользователей (например, в системе определения спама и оскорбительного контента).

### Обслуживание модели

Наконец, ни одна модель не вечна. Вы уже знаете о дрейфе понятий: со временем характеристики ваших реальных данных будут меняться, постепенно снижая актуальность модели. Срок службы системы музыкальных рекомендаций будет исчисляться неделями. Системы обнаружения мошеннических действий с кредитными картами — днями. Системы поиска изображений — в лучшем случае парой лет. После ввода модели в эксплуатацию вы должны быть готовы к обучению модели следующего поколения, которая придет на смену текущей. Для этого: 

- Cледите, как меняются реальные данные: возможно, появятся новые признаки или потребуется расширить или иным образом изменить набор меток; 

- Продолжайте собирать и маркировать данные и последовательно совершенствуйте процесс маркировки. В частности, особое внимание уделяйте сбору образцов, при классификации которых текущая модель допускает много ошибок, — такие образцы, вероятнее всего, помогут повысить качество модели. 


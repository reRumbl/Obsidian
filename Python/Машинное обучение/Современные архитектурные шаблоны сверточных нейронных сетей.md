**Архитектура модели** — это сумма решений, которые применялись при ее создании: использованные слои, их настройки и порядок соединения. Эти решения определяют пространство гипотез модели: пространство возможных функций, параметризованных весами модели, по которым градиентный спуск может выполнять поиск. Так же как при проектировании признаков, хорошее пространство гипотез кодирует имеющиеся знания о задаче и ее решении. Например, использование сверточных слоев предполагает предварительное знание, что соответствующие шаблоны, присутствующие в исходных изображениях, инвариантны в отношении переноса. Для эффективного обучения на данных обязательно нужно делать предположения о том, что нужно найти.

От архитектуры часто зависит успех или неудача модели. При выборе неправильной архитектуры модель может не добиться высоких показателей, и никакие обучающие данные не спасут ее. И наоборот, хорошая архитектура может ускорить обучение модели и позволит ей эффективно использовать доступные обучающие данные, уменьшая потребность в больших наборах данных. Хорошая архитектура модели уменьшает размер области поиска, или, иными словами, упрощает схождение к оптимальной точке области поиска. По аналогии с проектированием признаков и курированием данных цель архитектуры модели — упростить задачу для градиентного спуска. Градиентный спуск — довольно глупый поисковый процесс, поэтому ему нужна любая возможная помощь.

## Модульность, иерархия, многократное использование

Есть универсальный рецепт, помогающий упростить сложную систему: нужно лишь структурировать всю аморфную мешанину в модули, организовать модули в иерархию и многократно использовать одни и те же модули в разных местах по мере необходимости («многократное использование» — еще один термин для обозначения абстракции в этом контексте). Формула «модульность — иерархия — многократное использование» лежит в основе системной архитектуры практически во всех областях, где в принципе используется термин «архитектура». Само по себе глубокое обучение — всего лишь применение данного рецепта к непрерывной оптимизации методом градиентного спуска.
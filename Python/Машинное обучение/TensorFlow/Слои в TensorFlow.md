**Слой** — это модуль обработки данных, принимающий на входе и возвращающий на выходе один или несколько тензоров. Некоторые слои не сохраняют состояния, но чаще это не так: есть веса слоя — один или несколько тензоров, обучаемых с применением алгоритма стохастического градиентного спуска, которые вместе хранят знания, накапливаемые сетью.

Разным слоям соответствуют тензоры разных форматов и разные виды обработки данных. Например, простые векторные данные, хранящиеся в двумерных тензорах с формой (образцы, признаки), часто обрабатываются плотно связанными слоями, которые также называют полносвязными или плотными слоями ([[Классы|класс]] Dense в [[TensorFlow#^8b88d6|Keras]]). Ряды данных хранятся в трехмерных тензорах с формой (образцы, метки_времени, признаки) и обычно обрабатываются рекуррентными слоями, такими как LSTM, или одномерными сверточными слоями (Conv1D). Изображения хранятся в четырехмерных тензорах и обычно обрабатываются двумерными сверточными слоями (Conv2D).

Слои можно считать кубиками LEGO глубокого обучения. Библиотеки, подобные [[TensorFlow#^8b88d6|Keras]], делают это сравнение еще более явным: создание моделей глубокого обучения в [[TensorFlow#^8b88d6|Keras]] осуществляется путем объединения совместимых слоев в конвейеры обработки данных.

## Базовый класс Layer в TensorFlow.Keras

Простой прикладной интерфейс (API) должен иметь единую абстракцию, лежащую в основе всего. В [[TensorFlow#^8b88d6|Keras]] такой абстракцией служит класс слоев **Layer**. Все в [[TensorFlow#^8b88d6|Keras]] является либо слоем **Layer**, либо чем-то еще, что тесно взаимодействует со слоем **Layer**.

**Слой (Layer)** — это объект, инкапсулирующий некоторое состояние (веса) и некоторые вычисления (прямой проход). Веса обычно определяются с помощью метода build() (но также могут инициализироваться в конструкторе __init__()), а вычисления определяются в методе call().

**Слой Dense, реализованный как подкласс класса Layer:**

```Python
from tensorflow import keras


class SimpleDense(keras.layers.Layer):
	def __init__(self, units, activation=None):
		super().__init__()
		self.units = units
		self.activation = activation

	def build(self, input_shape):
		input_dim = input_shape[-1]
		self.W = self.add_weight(
			shape=(input_dim, self.units),
			initializer="random_normal"
		)
		self.b = self.add_weight(
			shape=(self.units,),
			initializer="zeros"
		)

	def call(self, inputs):
		y = tf.matmul(inputs, self.W) + self.b
		if self.activation is not None: 
			y = self.activation(y)
		return y


my_dense = SimpleDense(units=32, activation=tf.nn.relu)
input_tensor = tf.ones(shape=(2, 784))

output_tensor = my_dense(input_tensor)
print(output_tensor.shape)  # --> (2, 32)
```

## Автоматическое определение формы: построение слоев на лету

Подобно кубикам LEGO, состыковать можно только совместимые слои. Понятие совместимости слоев в нашем случае отражает лишь тот факт, что каждый слой принимает и возвращает тензоры определенной формы. В большинстве случаев библиотека [[TensorFlow#^8b88d6|Keras]] избавляет от необходимости беспокоиться о совместимости, поскольку слои, добавляемые в модели, автоматически конструируются так, чтобы соответствовать форме входного слоя.
**Обратный вызов** — это объект, который передается в модель через вызов `fit()` и который будет вызываться моделью в разные моменты обучения. Он имеет доступ ко всей информации о состоянии модели и ее качестве и может предпринимать следующие действия: прерывать обучение, сохранять модель, загружать разные наборы весов или как-то иначе изменять состояние модели.
\
**Примеры использования обратных вызовов:**

- Фиксация состояния модели в контрольных точках — сохранение текущего состояния модели в разные моменты в ходе обучения.

- Ранняя остановка — прерывание обучения, когда оценка потерь на проверочных данных перестает улучшаться (и, конечно, сохранение лучшего варианта модели, полученного в ходе обучения).

- Динамическая корректировка значений некоторых параметров в процессе обучения — например, шага обучения оптимизатора. 

- Журналирование оценок для обучающего и проверочного наборов данных в ходе обучения или визуализация представлений, получаемых моделью, по мере их обновления — индикатор выполнения в `fit()`.

[[TensorFlow#^8b88d6|Keras]] включает ряд встроенных обратных вызовов в модуле callbacks. Некоторые из них: 

- ModelCheckpoint.

- EarlyStopping.

- LearningRateScheduler.

- ReduceLROnPlateau.

- CSVLogger.

### Обратные вызовы EarlyStopping и ModelCheckpoint

Многие аспекты обучения модели нельзя предсказать заранее — например, количество эпох, обеспечивающее оптимальное значение потерь на проверочном наборе. В примерах, приводившихся до сих пор, использовалась стратегия обучения с достаточно большим количеством эпох. Таким способом достигался эффект переобучения: когда сначала выполнялся первый прогон, чтобы выяснить необходимое количество эпох обучения, а затем второй — новый — с этим количеством. Конечно, данная стратегия довольно расточительная. Гораздо лучше было бы остановить обучение, как только выяснится, что оценка потерь на проверочном наборе перестала улучшаться. Это можно реализовать с использованием обратного вызова **EarlyStopping**. 

Обратный вызов EarlyStopping прерывает процесс обучения, если находящаяся под наблюдением целевая метрика не улучшалась на протяжении заданного количества эпох. Он позволит остановить обучение после наступления эффекта переобучения и тем самым избежать повторного обучения модели для меньшего количества эпох. Данный обратный вызов обычно используется в комбинации с обратным вызовом **ModelCheckpoint**, который может сохранять состояние модели в ходе обучения (и при необходимости сохранять только лучшую модель: версию, достигшую лучшего качества к концу эпохи).

**Пример EarlyStopping + ModelCheckoint:**

```Python
callbacks_list = [  # Список обратных вызовов
	keras.callbacks.EarlyStopping(  # Остановка при ухудшении качества
		monitor='val_accuracy',  # Оценка на проверочных данных
		patience=2  # Остановка, если точность не улучшается в течение двух эпох
	),
	keras.callbacks.ModelCheckpoint(  # Сохраняет текущие веса после каждой эпохи
		filepath='model.keras',  # Путь к файлу модели
		monitor='val_loss',  # Если val_loss не улучшилось, то не перезаписывать
		save_best_only=True  # Сохраняет только лучшую версию модели
	)
]

model = get_mnist_model()
model.compile(
	optimizer='rmsprop',
	loss='sparse_categorical_crossentropy',
	metrics=['accuracy']  # Мы следим за точностью, она должна быть частью метрик
)
model.fit(
	train_images,
	train_labels,
	epochs=10,
	callbacks=callbacks_list,  # Обратные вызовы передаются через параметр callbacks
	validation_data=(val_images, val_labels)
)
```

*Примечание: Поскольку обратный вызов следит за потерями и точностью на проверочных данных, мы должны передать validation_data в вызов fit().*

## Создание собственных обратных вызовов

Если в ходе обучения потребуется выполнить какие-то особые действия, не предусмотренные ни одним из встроенных обратных вызовов, можно написать свой обратный вызов. Обратные вызовы реализуются путем создания подкласса класса keras.callbacks.Callback. Вы можете реализовать любые из следующих методов с говорящими именами, которые будут вызываться в соответствующие моменты в ходе обучения:

- on_epoch_begin — В начале эпохи.

- on_epoch_end — В конце эпохи.

- on_batch_begin — В начале пакета.

- on_batch_end — В конце пакета.

- on_train_begin — В начале обучения.

- on_train_end — В конце обучения.

Все эти методы вызываются с аргументом logs — словарем, содержащим информацию о предыдущем пакете, эпохе или цикле обучения (метрики обучения и проверки и т. д.). Методам `on_epoch_*` и on_`batch_*` также передается индекс эпохи или пакета в первом аргументе (целое число).

**Пример обратного вызова, с сохранением значений потерь после каждого пакета и сохранением графика потерь после каждой эпохи:**

```Python
from matplotlib import pyplot as plt


class LossHistory(keras.callbacks.Callback):
	def on_train_begin(self, logs):
		self.per_batch_losses = []

	def on_batch_end(self, batch, logs): 
		self.per_batch_losses.append(logs.get('loss'))

	def on_epoch_end(self, epoch, logs): 
		plt.clf() 
		plt.plot(
			range(len(self.per_batch_losses)), 
			self.per_batch_losses, 
			label='Потери на обучающих данных для каждого пакета'
		) 
		plt.xlabel(f'Пакеты (эпоха {epoch})')
		plt.ylabel('Потери')
		plt.legend()
		plt.savefig(f'plot_at_epoch_{epoch}')
		self.per_batch_losses = []


model = get_mnist_model()
model.compile(
	optimizer='rmsprop', 
	loss='sparse_categorical_crossentropy',
	metrics=['accuracy']
) 
model.fit(
	train_images, 
	train_labels, 
	epochs=10, 
	callbacks=[LossHistory()], 
	validation_data=(val_images, val_labels)
)
```
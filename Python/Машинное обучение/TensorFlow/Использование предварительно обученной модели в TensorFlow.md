Типичным и эффективным подходом к глубокому обучению на небольших наборах изображений является использование предварительно обученной модели. Предварительно обученная модель — это сохраненная модель, прежде обученная на большом наборе данных, обычно в рамках масштабной задачи классификации изображений. Если исходный набор данных достаточно велик и достаточно обобщен, то пространственная иерархия признаков, изученных моделью, может с успехом выступать в роли обобщенной модели видимого мира и использоваться во многих задачах компьютерного зрения, даже если новые задачи будут связаны с совершенно иными классами, отличными от встречавшихся в оригинальной задаче. Например, можно обучить сеть на изображениях из ImageNet (где подавляющее большинство классов — животные и бытовые предметы) и затем использовать ее для идентификации чего-то иного, например предметов мебели на изображениях. Такая переносимость изученных признаков между разными задачами — главное преимущество глубокого обучения перед многими более старыми приемами поверхностного обучения, которое делает глубокое обучение очень эффективным инструментом для решения задач с малым объемом данных.

**Есть два приема использования предварительно обученных сетей:** 

- Выделение признаков (feature extraction).

- Дообучение (fine-tuning).

## Выделение признаков

Выделение признаков заключается в использовании представлений, изученных предварительно обученной моделью, для выделения признаков из новых образцов. Эти признаки затем пропускаются через новый классификатор, обучаемый с нуля.

Например, в случае со сверточными нейронными сетями, процесс выделения признаков заключается в том, чтобы взять сверточную основу предварительно обученной сети, пропустить через нее новые данные и на основе вывода обучить новый классификатор. Если новый набор данных существенно отличается от набора, на котором обучалась оригинальная модель, возможно, большего успеха получится добиться, если использовать только несколько первых слоев модели, а не всю сверточную основу

**Загрузка предварительно обученной сверточной основы:**

```Python
from tensorflow import keras


conv_base = keras.applications.vgg16.VGG16(  
    weights='imagenet',  
    include_top=False,  
    input_shape=(180, 180, 3)  
)
```

**Здесь конструктору передаются три аргумента:** 

- Аргумент `weights` определяет источник весов для инициализации модели.

- Аргумент `include_top` определяет необходимость подключения к сети полносвязного классификатора. По умолчанию полносвязный классификатор определяет принадлежность изображения к 1000 классов. Так как мы намереваемся использовать свой полносвязный классификатор, мы не будем подключать его.

- Аргумент `input_shape` определяет форму тензоров с изображениями, которые будут подаваться на вход сети. Это необязательный аргумент: если опустить его, сеть сможет обрабатывать изображения любого размера. Мы передаем его, чтобы иметь возможность видеть, как уменьшается размер карт признаков с каждым новым слоем свертки и объединения.

**Далее можно пойти двумя путями:** 

- Пропустить наш набор данных через сверточную основу, записать получившийся [[Ndarray|массив NumPy]] на диск и затем использовать его как входные данные для отдельного полносвязного классификатора. Это быстрое и незатратное решение, потому что требует запускать сверточную основу только один раз для каждого входного изображения, а сверточная основа — самая дорогостоящая часть конвейера. Однако по той же причине этот прием не позволит использовать прием обогащения данных.

- Дополнить имеющуюся модель `conv_base` слоями `Dense` и пропустить все входные данные. Этот путь позволяет использовать обогащение данных, потому что каждое изображение проходит через сверточную основу каждый раз, когда попадает в модель. Однако по той же причине этот путь намного более затратный, чем первый.

*Первый вариант:*

```Python
import numpy as np  
  
  
def get_features_and_labels(dataset):  
    all_features = []  
    all_labels = []  
    for images, labels in dataset:  
        preprocessed_images = keras.applications.vgg16.preprocess_input(images)  
        features = conv_base.predict(preprocessed_images)  
        all_features.append(features)  
        all_labels.append(labels)  
    return np.concatenate(all_features), np.concatenate(all_labels)  
  
  
train_features, train_labels = get_features_and_labels(train_dataset)  
val_features, val_labels = get_features_and_labels(validation_dataset)  
test_features, test_labels = get_features_and_labels(test_dataset)

inputs = keras.Input(shape=(5, 5, 512))  
x = layers.Flatten()(inputs)  
x = layers.Dense(256)(x)  
x = layers.Dropout(0.5)(x)  
outputs = layers.Dense(1, activation='sigmoid')(x)  
model = keras.Model(inputs, outputs)  
  
model.compile(loss='binary_crossentropy',  
    optimizer='rmsprop',  
    metrics=['accuracy']  
)  
callbacks = [  
    keras.callbacks.ModelCheckpoint(  
    filepath='feature_extraction.keras',  
    save_best_only=True,  
    monitor='val_loss')  
]  
history = model.fit(  
    train_features, train_labels,  
    epochs=20,  
    validation_data=(val_features, val_labels),  
    callbacks=callbacks  
)
```

Обучение проходит очень быстро, потому что мы определили только два слоя `Dense` — одна эпоха длится меньше одной секунды даже при выполнении на CPU.

*Второй вариант:*

```Python
conv_base.trainable = False  # Заморозка ранее обученных весов

data_augmentation = keras.Sequential([  
    keras.layers.RandomFlip('horizontal'),  
    keras.layers.RandomRotation(0.1),  
    keras.layers.RandomZoom(0.2)  
])  
  
inputs = keras.Input(shape=(180, 180, 3))  
x = data_augmentation(inputs)  
x = keras.applications.vgg16.preprocess_input(x)  
x = conv_base(x)  
x = keras.layers.Flatten()(x)  
x = keras.layers.Dense(256)(x)  
x = keras.layers.Dropout(0.5)(x)  
outputs = keras.layers.Dense(1, activation='sigmoid')(x)  
model = keras.Model(inputs, outputs)  
  
model.compile(  
    loss='binary_crossentropy',  
    optimizer='rmsprop',  
    metrics=['accuracy']  
)

callbacks = [  
    keras.callbacks.ModelCheckpoint(  
    filepath='feature_extraction_with_data_augmentation.keras',  
    save_best_only=True,  
    monitor='val_loss')  
]  
history = model.fit(  
    train_dataset,  
    epochs=50,  
    validation_data=validation_dataset,  
    callbacks=callbacks  
)
```

В этом случае обучению будут подвергаться только веса из двух вновь добавленных слоев `Dense`, то есть всего четыре весовых тензора, по два на слой (главная весовая матрица и вектор смещений). Обратите внимание: чтобы эти изменения вступили в силу, необходимо скомпилировать модель. Если признак обучения весов изменяется после компиляции модели, необходимо снова перекомпилировать модель, иначе это изменение будет игнорироваться.

## Дообучение предварительно обученной модели

Другой широко используемый прием повторного использования модели, дополняющий выделение признаков, — дообучение (fine-tuning). Дообучение заключается в размораживании нескольких верхних слоев замороженной модели, которая использовалась для выделения признаков, и совместном обучении вновь добавленной части модели (в данном случае полносвязного классификатора) и этих верхних слоев. Данный прием называется дообучением, поскольку немного корректирует наиболее абстрактные представления в повторно используемой модели, чтобы сделать их более актуальными для конкретной задачи.

**Для дообучения сети нужно выполнить следующие шаги:**

- Добавить свою сеть поверх обученной базовой сети. 

- Заморозить базовую сеть.

- Обучить добавленную часть.

- Разморозить несколько слоев в базовой сети. (Обратите внимание, что не следует размораживать слои «пакетной нормализации»).

- Обучить эти слои и добавленную часть вместе.

Мы уже выполнили первые три шага в ходе выделения признаков. Теперь выполним шаг 4: разморозим `conv_base` и заморозим отдельные слои в ней.

**Заморозка всех слоев, кроме заданных и дообучение модели:**

```Python
conv_base.trainable = True 
for layer in conv_base.layers[:-4]: 
	layer.trainable = False

model.compile(
	loss='binary_crossentropy', 
	optimizer=keras.optimizers.RMSprop(learning_rate=1e-5), 
	metrics=['accuracy']
)
callbacks = [
	keras.callbacks.ModelCheckpoint(
		filepath='fine_tuning.keras', 
		save_best_only=True, 
		monitor='val_loss')
] 
history = model.fit(
	train_dataset, 
	epochs=30, 
	validation_data=validation_dataset, 
	callbacks=callbacks
)
```
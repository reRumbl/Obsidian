Модель глубокого обучения является графом слоев. В [[TensorFlow#^8b88d6|Keras]] модели представляют собой экземпляры [[Классы|класса]] Model. У Model есть [[Наследование|подклассы]], например последовательные модели Sequential ([[Наследование|подкласс]] [[Классы|класса]] Model) — простой стек слоев, отображающих единственный вход в единственный выход.

**Некоторые виды моделей нейронных сетей:**

- Сети с двумя ветвями (two-branch networks).

- Многоголовые сети (multihead networks).

- Входные блоки (inception blocks).

Выбор правильной архитектуры сети — больше искусство, чем наука. И хотя есть несколько проверенных методов и принципов, на которые можно положиться, только практика может помочь стать опытным архитектором нейронных сетей.

**После того как определена архитектура сети, нужно выбрать еще три параметра:**

- **Функцию потерь (целевую функцию)** — количественную оценку, которая будет минимизироваться в процессе обучения. Представляет собой меру успеха в решении стоящей задачи.

- **Оптимизатор** — определяет, как будет изменяться сеть под воздействием функции потерь. Реализует конкретный вариант стохастического градиентного спуска (Stochastic Gradient Descent, SGD).

- **Метрики** — показатели успеха (такие как точность классификации), за которыми будет вестись наблюдение во время обучения и проверки. Обучение, в отличие от потерь, не оптимизируется по данным показателям напрямую. Поэтому от метрик не требуется, чтобы они были дифференцированными.

## Обучение модели

После выбора функции потерь, оптимизатора и метрик можно использовать встроенные методы compile() и fit(), чтобы начать обучение модели. При желании можно также реализовать собственные циклы обучения.

### Compile

Метод **compile()** настраивает процесс обучения. Он принимает аргументы с оптимизатором, функцией потерь и метриками (в виде списка).

**Пример вызова compile():**

```Python
model = keras.Sequential([keras.layers.Dense(1)])
model.compile(
	optimizer="rmsprop",
	loss="mean_squared_error",
	metrics=["accuracy"]
)
```

В общем случае нет необходимости прописывать функции потерь, метрики или оптимизаторы с нуля, поскольку Keras предлагает широкий спектр встроенных опций, среди которых наверняка найдется то, что нужно для конкретной ситуации:

- **Оптимизаторы:** 

	- SGD (с импульсом или без). 
	
	- RMSprop.
	
	- Adam.
	
	- Adagrad и др.

- **Функции потерь:**

	- CategoricalCrossentropy.
	
	- SparseCategoricalCrossentropy.
	
	- BinaryCrossentropy.
	
	- MeanSquaredError.
	
	- KLDivergence.
	
	- CosineSimilarity и др.

- **Метрики:** 
	
	- CategoricalAccuracy.
	
	- SparseCategoricalAccuracy.
	
	- BinaryAccuracy. 
	
	- AUC.
	
	- Precision.
	
	- Recall и др.

### Fit

За вызовом compile() следует вызов **fit()**. Метод **fit()** реализует собственно цикл обучения. 

**Основные аргументы метода fit():**

- Данные для обучения (исходные данные и целевые значения). Обычно передаются в виде [[Ndarray|массивов NumPy]] или объекта Dataset из библиотеки TensorFlow.

- Количество эпох обучения - сколько раз должен повториться цикл обучения на переданных данных. 

- Размер пакета для использования в каждой эпохе обучения методом градиентного спуска - количество обучающих образцов, учитываемых при вычислении градиентов в одном шаге обновления весов.

**Пример вызова fit():**

```Python
history = model.fit(inputs, targets, epochs=5, batch_size=128)
```

Вызов **fit()** возвращает объект History с полем history — словарем, ключами которого служат имена метрик или строки (такие как "loss"), а значениями — списки значений соответствующих метрик, полученных в разные эпохи.

Для оценки качества модели — того, как она справляется со своей задачей на новых данных, — обычно принято выделять некоторую часть исходных данных в отдельную проверочную выборку: данные из этой выборки не участвуют в обучении модели, но используются для вычисления величины потерь и метрик. Проверочную выборку можно передать методу **fit()** в аргументе validation_data. По аналогии с обучающими данными проверочные данные могут передаваться в форме [[Ndarray|массива NumPy]] или объекта Dataset из библиотеки TensorFlow.

**Пример использования аргумента validation_data:**

```Python
model = keras.Sequential([keras.layers.Dense(1)])

model.compile(
	optimizer=keras.optimizers.RMSprop(learning_rate=0.1),
	loss=keras.losses.MeanSquaredError(),
	metrics=[keras.metrics.BinaryAccuracy()]
)

indices_permutation = np.random.permutation(len(inputs))
shuffled_inputs = inputs[indices_permutation]
shuffled_targets = targets[indices_permutation]

num_validation_samples = int(0.3 * len(inputs))

val_inputs = shuffled_inputs[:num_validation_samples]
val_targets = shuffled_targets[:num_validation_samples]

training_inputs = shuffled_inputs[num_validation_samples:]
training_targets = shuffled_targets[num_validation_samples:]

model.fit(
	training_inputs,
	training_targets,
	epochs=5,
	batch_size=16,
	validation_data=(val_inputs, val_targets)
)
```

**Потери на проверочных данных и метрики можно вычислить после завершения обучения вызовом метода evaluate():** 

```Python
loss_and_metrics = model.evaluate(val_inputs, val_targets, batch_size=128)
```

Метод evaluate() выполнит итерации по пакетам (размером batch_size) с переданными данными и вернет список скаляров, первый из которых — величина потерь на проверочных данных, а последующие — метрики. Если модель не имеет метрик, то возвращено будет только одно значение — величина потерь на проверочных данных (а не список).

## Использование модели после обучения

После обучения модель можно использовать для вычисления прогнозов на основе новых данных. Этот этап называется выводом. Простейший способ получить прогноз — вызвать модель.\

**Вызов модели:**

```Python
predictions = model(new_inputs)
```

Однако это подразумевает обработку сразу всех входных данных в new_inputs, что может оказаться невыполнимым, если, например, объем данных для прогнозирования слишком большой и для его обработки требуется больше памяти, чем имеется у вашего графического процессора. Лучший способ получить вывод — использовать метод predict(). Он выполнит обход данных, разбив их на небольшие пакеты, и вернет массив NumPy с прогнозами. В отличие от вызова, он также может обрабатывать объекты Dataset.

**Предсказание при помощи predict():**

```Python
predictions = model.predict(new_inputs, batch_size=128)
```
